{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# GAN-based Semi-supervised Learning.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train = pd.read_csv('../datasets/fashionmnist/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('../datasets/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "y_train = train['label'].values\n",
    "X_train = train.drop('label', axis=1)\n",
    "\n",
    "mm_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = mm_scaler.fit_transform(X_train)\n",
    "real_samples, dim = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 256\n",
    "N_BATCHES = real_samples / BATCH_SIZE\n",
    "N_EPOCHS = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "REAL_INPUT_UNITS = 784\n",
    "HIDDEN_UNITS = 256\n",
    "NOISE_INPUT_UNITS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_imgs, hidden_units, output_dim, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        hidden_layer = tf.layers.dense(noise_imgs, hidden_units, activation=tf.nn.relu)\n",
    "        gen_imgs = tf.layers.dense(hidden_layer, output_dim, activation=tf.nn.sigmoid)\n",
    "    return gen_imgs\n",
    "\n",
    "def discriminator(imgs, hidden_units, output_dim, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        hidden_layer = tf.layers.dense(imgs, hidden_units, activation=tf.nn.relu)\n",
    "        dis_logits = tf.layers.dense(hidden_layer, output_dim, activation=None)\n",
    "        gan_logits = tf.reduce_logsumexp(dis_logits, 1)\n",
    "        return dis_logits, gan_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80301625 0.047615454\n",
      "0.61369735 0.016793402\n",
      "0.44146788 0.0100765955\n",
      "0.45719156 0.0063986494\n",
      "0.41561723 0.0057730097\n",
      "0.3795433 0.003490974\n",
      "0.42114854 0.0038486235\n",
      "0.36253962 0.003399781\n",
      "0.39586017 0.0028122854\n",
      "0.33145764 0.0019702595\n",
      "0.3016534 0.0016871603\n",
      "0.39291728 0.0027649254\n",
      "0.34778517 0.0015982662\n",
      "0.35897377 0.0016376269\n",
      "0.27861732 0.0012384108\n",
      "0.30271044 0.0012724117\n",
      "0.36662385 0.002097226\n",
      "0.38058105 0.0013695841\n",
      "0.4041912 0.0012133655\n",
      "0.30450007 0.00081690855\n",
      "0.29131663 0.0008432041\n",
      "0.28629848 0.00079838425\n",
      "0.3200727 0.0006395673\n",
      "0.30926567 0.0008897899\n",
      "0.29118103 0.00069293485\n",
      "0.33106658 0.00068206125\n",
      "0.30551592 0.00061024894\n",
      "0.33176863 0.00061006274\n",
      "0.23904058 0.0005838803\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ec171ea3ec3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mbatch_real_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mbatch_real_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_imgs = tf.placeholder(tf.float32, shape=(None, REAL_INPUT_UNITS), name='real_imgs')\n",
    "real_labels = tf.placeholder(tf.int32, shape=(None) , name='real_labels')\n",
    "\n",
    "noise_imgs = tf.placeholder(tf.float32, shape=(None, NOISE_INPUT_UNITS), name='noise_imgs')\n",
    "\n",
    "gen_imgs = generator(noise_imgs, HIDDEN_UNITS, REAL_INPUT_UNITS)\n",
    "\n",
    "dis_real_logits, gan_real_logits = discriminator(real_imgs, HIDDEN_UNITS, 10)\n",
    "dis_fake_logits, gan_fake_logits = discriminator(gen_imgs, HIDDEN_UNITS, 10, reuse=True)\n",
    "\n",
    "gan_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_real_logits, labels=tf.ones_like(gan_real_logits)))\n",
    "gan_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_fake_logits, labels=tf.zeros_like(gan_fake_logits)))                           \n",
    "\n",
    "unsupervised_loss = gan_real_loss + gan_fake_loss\n",
    "\n",
    "supervised_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=dis_real_logits, labels=real_labels))\n",
    "\n",
    "total_loss = unsupervised_loss + supervised_loss\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "dis_vars = [var for var in train_vars if var.name.startswith('discriminator')]\n",
    "dis_train_opt = tf.train.AdamOptimizer(LEARNING_RATE).minimize(total_loss, var_list=dis_vars)\n",
    "\n",
    "gen_vars = [var for var in train_vars if var.name.startswith('generator')]\n",
    "gen_train_opt = tf.train.AdamOptimizer(LEARNING_RATE).minimize(unsupervised_loss, var_list=gen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "samples = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    max_dis_loss = -np.inf\n",
    "    min_gen_loss = np.inf\n",
    "    \n",
    "    \n",
    "    for iteration in range(N_EPOCHS):\n",
    "        for i in range(N_BATCHES):\n",
    "            np.random.seed(iteration * N_BATCHES + i)\n",
    "            \n",
    "            indices = np.random.randint(real_samples, size=BATCH_SIZE)\n",
    "            \n",
    "            batch_real_imgs = X_train[indices]\n",
    "            batch_real_labels = y_train[indices]\n",
    "            \n",
    "            batch_noise_imgs = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_INPUT_UNITS))\n",
    "            \n",
    "            sess.run(dis_train_opt, feed_dict={real_imgs: batch_real_imgs, real_labels: batch_real_labels, noise_imgs: batch_noise_imgs})\n",
    "            sess.run(gen_train_opt, feed_dict={real_imgs: batch_real_imgs, noise_imgs: batch_noise_imgs})\n",
    "            \n",
    "        d_loss, g_loss = sess.run([total_loss, unsupervised_loss], feed_dict={real_imgs: batch_real_imgs, real_labels: batch_real_labels, noise_imgs: batch_noise_imgs})\n",
    "        print d_loss, g_loss\n",
    "\n",
    "#         sample_noise = np.random.uniform(-1, 1, size=(20, NOISE_INPUT_UNITS))\n",
    "\n",
    "#         gen_samples = sess.run(generator(noise_img, HIDDEN_UNITS, REAL_INPUT_UNITS, reuse=True),\n",
    "#                            feed_dict={noise_img: sample_noise})\n",
    "#         samples.append(gen_samples)\n",
    "    \n",
    "#         # 存储checkpoints       \n",
    "#         if max_dis_loss < d_loss and min_gen_loss > g_loss:\n",
    "#             max_dis_loss = d_loss\n",
    "#             min_gen_loss = g_loss\n",
    "#             saver.save(sess, 'models/section_3.8/my_final_model.ckpt')\n",
    "        \n",
    "#             print 'Iteration %d: d_loss = %f, g_loss = %f' % (iteration + 1, max_dis_loss, min_gen_loss)\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
