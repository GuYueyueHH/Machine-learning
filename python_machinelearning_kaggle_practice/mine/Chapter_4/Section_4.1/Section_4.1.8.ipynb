{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:26: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.355240\n",
      "Dev_Accuracy @ Iteration 1: 0.864900\n",
      "#### Save model @ Iteration 1 ####\n",
      "Iteration 2, loss = 0.300771\n",
      "Dev_Accuracy @ Iteration 2: 0.872900\n",
      "#### Save model @ Iteration 2 ####\n",
      "Iteration 3, loss = 0.265138\n",
      "Dev_Accuracy @ Iteration 3: 0.877400\n",
      "#### Save model @ Iteration 3 ####\n",
      "Iteration 4, loss = 0.244482\n",
      "Dev_Accuracy @ Iteration 4: 0.877700\n",
      "#### Save model @ Iteration 4 ####\n",
      "Iteration 5, loss = 0.222487\n",
      "Dev_Accuracy @ Iteration 5: 0.879800\n",
      "#### Save model @ Iteration 5 ####\n",
      "Iteration 6, loss = 0.211776\n",
      "Dev_Accuracy @ Iteration 6: 0.881100\n",
      "#### Save model @ Iteration 6 ####\n",
      "Iteration 7, loss = 0.181120\n",
      "Dev_Accuracy @ Iteration 7: 0.883900\n",
      "#### Save model @ Iteration 7 ####\n",
      "Iteration 8, loss = 0.162092\n",
      "Dev_Accuracy @ Iteration 8: 0.886300\n",
      "#### Save model @ Iteration 8 ####\n",
      "Iteration 9, loss = 0.145495\n",
      "Dev_Accuracy @ Iteration 9: 0.886800\n",
      "#### Save model @ Iteration 9 ####\n",
      "Iteration 10, loss = 0.138037\n",
      "Dev_Accuracy @ Iteration 10: 0.887700\n",
      "#### Save model @ Iteration 10 ####\n",
      "Iteration 11, loss = 0.132747\n",
      "Dev_Accuracy @ Iteration 11: 0.883600\n",
      "Iteration 12, loss = 0.114826\n",
      "Dev_Accuracy @ Iteration 12: 0.884700\n",
      "Iteration 13, loss = 0.100276\n",
      "Dev_Accuracy @ Iteration 13: 0.888800\n",
      "#### Save model @ Iteration 13 ####\n",
      "Iteration 14, loss = 0.100325\n",
      "Dev_Accuracy @ Iteration 14: 0.882500\n",
      "Iteration 15, loss = 0.080396\n",
      "Dev_Accuracy @ Iteration 15: 0.892800\n",
      "#### Save model @ Iteration 15 ####\n",
      "Iteration 16, loss = 0.081888\n",
      "Dev_Accuracy @ Iteration 16: 0.886200\n",
      "Iteration 17, loss = 0.076543\n",
      "Dev_Accuracy @ Iteration 17: 0.887600\n",
      "Iteration 18, loss = 0.071495\n",
      "Dev_Accuracy @ Iteration 18: 0.884000\n",
      "Iteration 19, loss = 0.058958\n",
      "Dev_Accuracy @ Iteration 19: 0.890500\n",
      "Iteration 20, loss = 0.051678\n",
      "Dev_Accuracy @ Iteration 20: 0.886700\n",
      "Iteration 21, loss = 0.043703\n",
      "Dev_Accuracy @ Iteration 21: 0.888500\n",
      "Iteration 22, loss = 0.039892\n",
      "Dev_Accuracy @ Iteration 22: 0.889600\n",
      "Iteration 23, loss = 0.038676\n",
      "Dev_Accuracy @ Iteration 23: 0.890400\n",
      "Iteration 24, loss = 0.035254\n",
      "Dev_Accuracy @ Iteration 24: 0.892800\n",
      "Iteration 25, loss = 0.041539\n",
      "Dev_Accuracy @ Iteration 25: 0.887200\n",
      "Iteration 26, loss = 0.029124\n",
      "Dev_Accuracy @ Iteration 26: 0.889400\n",
      "Iteration 27, loss = 0.028385\n",
      "Dev_Accuracy @ Iteration 27: 0.890300\n",
      "Iteration 28, loss = 0.024276\n",
      "Dev_Accuracy @ Iteration 28: 0.890200\n",
      "Iteration 29, loss = 0.029622\n",
      "Dev_Accuracy @ Iteration 29: 0.885100\n",
      "Iteration 30, loss = 0.024222\n",
      "Dev_Accuracy @ Iteration 30: 0.887600\n",
      "Iteration 31, loss = 0.022397\n",
      "Dev_Accuracy @ Iteration 31: 0.886800\n",
      "Iteration 32, loss = 0.025546\n",
      "Dev_Accuracy @ Iteration 32: 0.887400\n",
      "Iteration 33, loss = 0.019631\n",
      "Dev_Accuracy @ Iteration 33: 0.888000\n",
      "Iteration 34, loss = 0.023212\n",
      "Dev_Accuracy @ Iteration 34: 0.887300\n",
      "Iteration 35, loss = 0.017654\n",
      "Dev_Accuracy @ Iteration 35: 0.887800\n",
      "Iteration 36, loss = 0.031571\n",
      "Dev_Accuracy @ Iteration 36: 0.887100\n",
      "Iteration 37, loss = 0.022689\n",
      "Dev_Accuracy @ Iteration 37: 0.887600\n",
      "Iteration 38, loss = 0.013962\n",
      "Dev_Accuracy @ Iteration 38: 0.886400\n",
      "Iteration 39, loss = 0.010198\n",
      "Dev_Accuracy @ Iteration 39: 0.890700\n",
      "Iteration 40, loss = 0.010204\n",
      "Dev_Accuracy @ Iteration 40: 0.890400\n",
      "Iteration 41, loss = 0.006021\n",
      "Dev_Accuracy @ Iteration 41: 0.892400\n",
      "Iteration 42, loss = 0.007237\n",
      "Dev_Accuracy @ Iteration 42: 0.890300\n",
      "Iteration 43, loss = 0.006817\n",
      "Dev_Accuracy @ Iteration 43: 0.892200\n",
      "Iteration 44, loss = 0.084753\n",
      "Dev_Accuracy @ Iteration 44: 0.870100\n",
      "Iteration 45, loss = 0.027764\n",
      "Dev_Accuracy @ Iteration 45: 0.883300\n",
      "Iteration 46, loss = 0.013596\n",
      "Dev_Accuracy @ Iteration 46: 0.886400\n",
      "Iteration 47, loss = 0.010080\n",
      "Dev_Accuracy @ Iteration 47: 0.890700\n",
      "Iteration 48, loss = 0.005198\n",
      "Dev_Accuracy @ Iteration 48: 0.890800\n",
      "Iteration 49, loss = 0.003704\n",
      "Dev_Accuracy @ Iteration 49: 0.891000\n",
      "Iteration 50, loss = 0.002993\n",
      "Dev_Accuracy @ Iteration 50: 0.891500\n",
      "INFO:tensorflow:Restoring parameters from ../models/section_4.1.6/baseline_model.ckpt\n",
      "验证集上的分类准确率为：0.892800\n",
      "测试集上的分类准确率为：0.898500\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "采用TensorFlow内置的前馈神经网络模块，进行时装图像的分类。\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv('../datasets/fashionmnist/fashion-mnist_train.csv')\n",
    "\n",
    "train, dev = train_test_split(train, test_size=10000, random_state=2019)\n",
    "\n",
    "test = pd.read_csv('../datasets/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "y_train = train['label'].values\n",
    "y_dev = dev['label'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "X_train = train.drop('label', axis=1)\n",
    "X_dev = dev.drop('label', axis=1)\n",
    "X_test = test.drop('label', axis=1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_dev = ss.transform(X_dev)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "train_samples, n_features = np.shape(X_train)\n",
    "dev_samples = len(X_dev)\n",
    "test_samples = len(X_test)\n",
    "\n",
    "print train_samples, dev_samples, test_samples\n",
    "\n",
    "import tensorflow as tf\n",
    "        \n",
    "n_inputs = n_features\n",
    "n_hidden = 300\n",
    "n_outputs = 10\n",
    "batch_size = 256\n",
    "n_batches = train_samples / batch_size\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "\n",
    "#采用TensorFlow内置的前馈神经网络模块，搭建网络。\n",
    "hidden = tf.layers.dense(X, n_hidden, name='hidden', activation=tf.nn.tanh)\n",
    "logits = tf.layers.dense(hidden, n_outputs, name='outputs')\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    max_dev_acc = -np.inf\n",
    "    \n",
    "    for iteration in range(n_epochs):\n",
    "        for i in range(n_batches):\n",
    "            np.random.seed(iteration * n_batches + i)\n",
    "            indices = np.random.randint(train_samples, size=batch_size)\n",
    "            X_batch = X_train[indices]\n",
    "            y_batch = y_train[indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        print 'Iteration %d, loss = %f' % (iteration + 1, loss.eval(feed_dict = {X: X_train, y: y_train}))\n",
    "        \n",
    "        dev_acc = accuracy.eval(feed_dict = {X: X_dev, y: y_dev})\n",
    "        \n",
    "        print 'Dev_Accuracy @ Iteration %d: %f' % (iteration + 1, dev_acc)\n",
    "        if max_dev_acc < dev_acc:\n",
    "            saver.save(sess, '../models/section_4.1.8/baseline_model.ckpt')\n",
    "            print '#### Save model @ Iteration %d ####' %(iteration + 1)\n",
    "            max_dev_acc = dev_acc\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    # 加载所有相关参数。\n",
    "    saver.restore(sess, '../models/section_4.1.8/baseline_model.ckpt')\n",
    "    print '验证集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_dev, y: y_dev})\n",
    "    print '测试集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_test, y: y_test})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:26: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.366766\n",
      "Dev_Accuracy @ Iteration 1: 0.858600\n",
      "#### Save model @ Iteration 1 ####\n",
      "Iteration 2, loss = 0.318700\n",
      "Dev_Accuracy @ Iteration 2: 0.865000\n",
      "#### Save model @ Iteration 2 ####\n",
      "Iteration 3, loss = 0.288955\n",
      "Dev_Accuracy @ Iteration 3: 0.873100\n",
      "#### Save model @ Iteration 3 ####\n",
      "Iteration 4, loss = 0.269300\n",
      "Dev_Accuracy @ Iteration 4: 0.875000\n",
      "#### Save model @ Iteration 4 ####\n",
      "Iteration 5, loss = 0.257118\n",
      "Dev_Accuracy @ Iteration 5: 0.871000\n",
      "Iteration 6, loss = 0.238651\n",
      "Dev_Accuracy @ Iteration 6: 0.877200\n",
      "#### Save model @ Iteration 6 ####\n",
      "Iteration 7, loss = 0.219480\n",
      "Dev_Accuracy @ Iteration 7: 0.879800\n",
      "#### Save model @ Iteration 7 ####\n",
      "Iteration 8, loss = 0.209469\n",
      "Dev_Accuracy @ Iteration 8: 0.883400\n",
      "#### Save model @ Iteration 8 ####\n",
      "Iteration 9, loss = 0.203819\n",
      "Dev_Accuracy @ Iteration 9: 0.878300\n",
      "Iteration 10, loss = 0.183640\n",
      "Dev_Accuracy @ Iteration 10: 0.886900\n",
      "#### Save model @ Iteration 10 ####\n",
      "Iteration 11, loss = 0.174638\n",
      "Dev_Accuracy @ Iteration 11: 0.885600\n",
      "Iteration 12, loss = 0.166134\n",
      "Dev_Accuracy @ Iteration 12: 0.885900\n",
      "Iteration 13, loss = 0.162031\n",
      "Dev_Accuracy @ Iteration 13: 0.887300\n",
      "#### Save model @ Iteration 13 ####\n",
      "Iteration 14, loss = 0.152759\n",
      "Dev_Accuracy @ Iteration 14: 0.885500\n",
      "Iteration 15, loss = 0.154054\n",
      "Dev_Accuracy @ Iteration 15: 0.883700\n",
      "Iteration 16, loss = 0.137347\n",
      "Dev_Accuracy @ Iteration 16: 0.888400\n",
      "#### Save model @ Iteration 16 ####\n",
      "Iteration 17, loss = 0.131835\n",
      "Dev_Accuracy @ Iteration 17: 0.886700\n",
      "Iteration 18, loss = 0.124681\n",
      "Dev_Accuracy @ Iteration 18: 0.886100\n",
      "Iteration 19, loss = 0.122868\n",
      "Dev_Accuracy @ Iteration 19: 0.887300\n",
      "Iteration 20, loss = 0.111894\n",
      "Dev_Accuracy @ Iteration 20: 0.889000\n",
      "#### Save model @ Iteration 20 ####\n",
      "Iteration 21, loss = 0.108178\n",
      "Dev_Accuracy @ Iteration 21: 0.885800\n",
      "Iteration 22, loss = 0.102317\n",
      "Dev_Accuracy @ Iteration 22: 0.887800\n",
      "Iteration 23, loss = 0.104371\n",
      "Dev_Accuracy @ Iteration 23: 0.887900\n",
      "Iteration 24, loss = 0.096146\n",
      "Dev_Accuracy @ Iteration 24: 0.890700\n",
      "#### Save model @ Iteration 24 ####\n",
      "Iteration 25, loss = 0.091175\n",
      "Dev_Accuracy @ Iteration 25: 0.891700\n",
      "#### Save model @ Iteration 25 ####\n",
      "Iteration 26, loss = 0.088955\n",
      "Dev_Accuracy @ Iteration 26: 0.888200\n",
      "Iteration 27, loss = 0.094578\n",
      "Dev_Accuracy @ Iteration 27: 0.888400\n",
      "Iteration 28, loss = 0.078410\n",
      "Dev_Accuracy @ Iteration 28: 0.891900\n",
      "#### Save model @ Iteration 28 ####\n",
      "Iteration 29, loss = 0.074082\n",
      "Dev_Accuracy @ Iteration 29: 0.890000\n",
      "Iteration 30, loss = 0.072979\n",
      "Dev_Accuracy @ Iteration 30: 0.890300\n",
      "Iteration 31, loss = 0.066322\n",
      "Dev_Accuracy @ Iteration 31: 0.892600\n",
      "#### Save model @ Iteration 31 ####\n",
      "Iteration 32, loss = 0.062005\n",
      "Dev_Accuracy @ Iteration 32: 0.893700\n",
      "#### Save model @ Iteration 32 ####\n",
      "Iteration 33, loss = 0.068851\n",
      "Dev_Accuracy @ Iteration 33: 0.886500\n",
      "Iteration 34, loss = 0.061198\n",
      "Dev_Accuracy @ Iteration 34: 0.889000\n",
      "Iteration 35, loss = 0.054542\n",
      "Dev_Accuracy @ Iteration 35: 0.890900\n",
      "Iteration 36, loss = 0.058015\n",
      "Dev_Accuracy @ Iteration 36: 0.890600\n",
      "Iteration 37, loss = 0.056291\n",
      "Dev_Accuracy @ Iteration 37: 0.888600\n",
      "Iteration 38, loss = 0.050056\n",
      "Dev_Accuracy @ Iteration 38: 0.888100\n",
      "Iteration 39, loss = 0.052743\n",
      "Dev_Accuracy @ Iteration 39: 0.891500\n",
      "Iteration 40, loss = 0.050387\n",
      "Dev_Accuracy @ Iteration 40: 0.889100\n",
      "Iteration 41, loss = 0.043279\n",
      "Dev_Accuracy @ Iteration 41: 0.892200\n",
      "Iteration 42, loss = 0.051021\n",
      "Dev_Accuracy @ Iteration 42: 0.889900\n",
      "Iteration 43, loss = 0.043395\n",
      "Dev_Accuracy @ Iteration 43: 0.892700\n",
      "Iteration 44, loss = 0.041926\n",
      "Dev_Accuracy @ Iteration 44: 0.890700\n",
      "Iteration 45, loss = 0.046048\n",
      "Dev_Accuracy @ Iteration 45: 0.888900\n",
      "Iteration 46, loss = 0.038189\n",
      "Dev_Accuracy @ Iteration 46: 0.892500\n",
      "Iteration 47, loss = 0.037533\n",
      "Dev_Accuracy @ Iteration 47: 0.892700\n",
      "Iteration 48, loss = 0.034508\n",
      "Dev_Accuracy @ Iteration 48: 0.892700\n",
      "Iteration 49, loss = 0.031774\n",
      "Dev_Accuracy @ Iteration 49: 0.891000\n",
      "Iteration 50, loss = 0.031423\n",
      "Dev_Accuracy @ Iteration 50: 0.890400\n",
      "INFO:tensorflow:Restoring parameters from ../models/section_4.1.6/dropout_model.ckpt\n",
      "验证集上的分类准确率为：0.893700\n",
      "测试集上的分类准确率为：0.893100\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "采用TensorFlow内置的前馈神经网络模块，进行时装图像的分类。\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv('../datasets/fashionmnist/fashion-mnist_train.csv')\n",
    "\n",
    "train, dev = train_test_split(train, test_size=10000, random_state=2019)\n",
    "\n",
    "test = pd.read_csv('../datasets/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "y_train = train['label'].values\n",
    "y_dev = dev['label'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "X_train = train.drop('label', axis=1)\n",
    "X_dev = dev.drop('label', axis=1)\n",
    "X_test = test.drop('label', axis=1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_dev = ss.transform(X_dev)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "train_samples, n_features = np.shape(X_train)\n",
    "dev_samples = len(X_dev)\n",
    "test_samples = len(X_test)\n",
    "\n",
    "print train_samples, dev_samples, test_samples\n",
    "\n",
    "import tensorflow as tf\n",
    "        \n",
    "n_inputs = n_features\n",
    "n_hidden = 300\n",
    "n_outputs = 10\n",
    "batch_size = 256\n",
    "n_batches = train_samples / batch_size\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "dropout_rate = 0.2\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "#输入层后增加一个dropout层。\n",
    "X_dropout = tf.layers.dropout(X, rate=dropout_rate, name='X_dropout', training=is_training)\n",
    "\n",
    "#采用TensorFlow内置的前馈神经网络模块，搭建网络。\n",
    "hidden = tf.layers.dense(X, n_hidden, name='hidden', activation=tf.nn.tanh)\n",
    "\n",
    "#隐藏层后再增加一个dropout层。\n",
    "hidden_dropout = tf.layers.dropout(hidden, rate=dropout_rate, training=is_training, name='hidden_dropout')\n",
    "\n",
    "logits = tf.layers.dense(hidden_dropout, n_outputs, name='outputs')\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    max_dev_acc = -np.inf\n",
    "    \n",
    "    for iteration in range(n_epochs):\n",
    "        for i in range(n_batches):\n",
    "            np.random.seed(iteration * n_batches + i)\n",
    "            indices = np.random.randint(train_samples, size=batch_size)\n",
    "            X_batch = X_train[indices]\n",
    "            y_batch = y_train[indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, is_training: True})\n",
    "        print 'Iteration %d, loss = %f' % (iteration + 1, loss.eval(feed_dict = {X: X_train, y: y_train, is_training: False}))\n",
    "        \n",
    "        dev_acc = accuracy.eval(feed_dict = {X: X_dev, y: y_dev, is_training: False})\n",
    "        \n",
    "        print 'Dev_Accuracy @ Iteration %d: %f' % (iteration + 1, dev_acc)\n",
    "        if max_dev_acc < dev_acc:\n",
    "            saver.save(sess, '../models/section_4.1.8/dropout_model.ckpt')\n",
    "            print '#### Save model @ Iteration %d ####' %(iteration + 1)\n",
    "            max_dev_acc = dev_acc\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    # 加载所有相关参数。\n",
    "    saver.restore(sess, '../models/section_4.1.8/dropout_model.ckpt')\n",
    "    print '验证集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_dev, y: y_dev, is_training: False})\n",
    "    print '测试集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_test, y: y_test, is_training: False})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
