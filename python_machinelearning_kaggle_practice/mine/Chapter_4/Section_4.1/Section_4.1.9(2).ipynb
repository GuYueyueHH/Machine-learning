{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:26: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.497422\n",
      "Dev_Accuracy @ Iteration 1: 0.837900\n",
      "#### Save model @ Iteration 1 ####\n",
      "Iteration 2, loss = 0.392308\n",
      "Dev_Accuracy @ Iteration 2: 0.857200\n",
      "#### Save model @ Iteration 2 ####\n",
      "Iteration 3, loss = 0.353536\n",
      "Dev_Accuracy @ Iteration 3: 0.865200\n",
      "#### Save model @ Iteration 3 ####\n",
      "Iteration 4, loss = 0.330352\n",
      "Dev_Accuracy @ Iteration 4: 0.866900\n",
      "#### Save model @ Iteration 4 ####\n",
      "Iteration 5, loss = 0.307563\n",
      "Dev_Accuracy @ Iteration 5: 0.869600\n",
      "#### Save model @ Iteration 5 ####\n",
      "Iteration 6, loss = 0.279236\n",
      "Dev_Accuracy @ Iteration 6: 0.877500\n",
      "#### Save model @ Iteration 6 ####\n",
      "Iteration 7, loss = 0.261283\n",
      "Dev_Accuracy @ Iteration 7: 0.877400\n",
      "Iteration 8, loss = 0.243304\n",
      "Dev_Accuracy @ Iteration 8: 0.881000\n",
      "#### Save model @ Iteration 8 ####\n",
      "Iteration 9, loss = 0.224410\n",
      "Dev_Accuracy @ Iteration 9: 0.882700\n",
      "#### Save model @ Iteration 9 ####\n",
      "Iteration 10, loss = 0.212178\n",
      "Dev_Accuracy @ Iteration 10: 0.882800\n",
      "#### Save model @ Iteration 10 ####\n",
      "Iteration 11, loss = 0.197593\n",
      "Dev_Accuracy @ Iteration 11: 0.885600\n",
      "#### Save model @ Iteration 11 ####\n",
      "Iteration 12, loss = 0.189783\n",
      "Dev_Accuracy @ Iteration 12: 0.880300\n",
      "Iteration 13, loss = 0.174276\n",
      "Dev_Accuracy @ Iteration 13: 0.884700\n",
      "Iteration 14, loss = 0.166548\n",
      "Dev_Accuracy @ Iteration 14: 0.882800\n",
      "Iteration 15, loss = 0.150145\n",
      "Dev_Accuracy @ Iteration 15: 0.886100\n",
      "#### Save model @ Iteration 15 ####\n",
      "Iteration 16, loss = 0.137163\n",
      "Dev_Accuracy @ Iteration 16: 0.886000\n",
      "Iteration 17, loss = 0.129871\n",
      "Dev_Accuracy @ Iteration 17: 0.885700\n",
      "Iteration 18, loss = 0.117353\n",
      "Dev_Accuracy @ Iteration 18: 0.884000\n",
      "Iteration 19, loss = 0.107224\n",
      "Dev_Accuracy @ Iteration 19: 0.887900\n",
      "#### Save model @ Iteration 19 ####\n",
      "Iteration 20, loss = 0.094265\n",
      "Dev_Accuracy @ Iteration 20: 0.889100\n",
      "#### Save model @ Iteration 20 ####\n",
      "Iteration 21, loss = 0.091482\n",
      "Dev_Accuracy @ Iteration 21: 0.885400\n",
      "Iteration 22, loss = 0.079021\n",
      "Dev_Accuracy @ Iteration 22: 0.888700\n",
      "Iteration 23, loss = 0.083030\n",
      "Dev_Accuracy @ Iteration 23: 0.885300\n",
      "Iteration 24, loss = 0.065610\n",
      "Dev_Accuracy @ Iteration 24: 0.887300\n",
      "Iteration 25, loss = 0.067984\n",
      "Dev_Accuracy @ Iteration 25: 0.887500\n",
      "Iteration 26, loss = 0.053515\n",
      "Dev_Accuracy @ Iteration 26: 0.889000\n",
      "Iteration 27, loss = 0.051318\n",
      "Dev_Accuracy @ Iteration 27: 0.887200\n",
      "Iteration 28, loss = 0.044777\n",
      "Dev_Accuracy @ Iteration 28: 0.891400\n",
      "#### Save model @ Iteration 28 ####\n",
      "Iteration 29, loss = 0.048907\n",
      "Dev_Accuracy @ Iteration 29: 0.885400\n",
      "Iteration 30, loss = 0.043606\n",
      "Dev_Accuracy @ Iteration 30: 0.886900\n",
      "Iteration 31, loss = 0.035888\n",
      "Dev_Accuracy @ Iteration 31: 0.888200\n",
      "Iteration 32, loss = 0.033425\n",
      "Dev_Accuracy @ Iteration 32: 0.889100\n",
      "Iteration 33, loss = 0.028650\n",
      "Dev_Accuracy @ Iteration 33: 0.887000\n",
      "Iteration 34, loss = 0.035997\n",
      "Dev_Accuracy @ Iteration 34: 0.883500\n",
      "Iteration 35, loss = 0.029332\n",
      "Dev_Accuracy @ Iteration 35: 0.888600\n",
      "Iteration 36, loss = 0.022137\n",
      "Dev_Accuracy @ Iteration 36: 0.887900\n",
      "Iteration 37, loss = 0.025634\n",
      "Dev_Accuracy @ Iteration 37: 0.889600\n",
      "Iteration 38, loss = 0.014571\n",
      "Dev_Accuracy @ Iteration 38: 0.889900\n",
      "Iteration 39, loss = 0.017880\n",
      "Dev_Accuracy @ Iteration 39: 0.886700\n",
      "Iteration 40, loss = 0.014421\n",
      "Dev_Accuracy @ Iteration 40: 0.892400\n",
      "#### Save model @ Iteration 40 ####\n",
      "Iteration 41, loss = 0.016485\n",
      "Dev_Accuracy @ Iteration 41: 0.888900\n",
      "Iteration 42, loss = 0.038217\n",
      "Dev_Accuracy @ Iteration 42: 0.883600\n",
      "Iteration 43, loss = 0.014486\n",
      "Dev_Accuracy @ Iteration 43: 0.885800\n",
      "Iteration 44, loss = 0.010953\n",
      "Dev_Accuracy @ Iteration 44: 0.890200\n",
      "Iteration 45, loss = 0.008837\n",
      "Dev_Accuracy @ Iteration 45: 0.892600\n",
      "#### Save model @ Iteration 45 ####\n",
      "Iteration 46, loss = 0.011611\n",
      "Dev_Accuracy @ Iteration 46: 0.889500\n",
      "Iteration 47, loss = 0.025990\n",
      "Dev_Accuracy @ Iteration 47: 0.888300\n",
      "Iteration 48, loss = 0.010640\n",
      "Dev_Accuracy @ Iteration 48: 0.890800\n",
      "Iteration 49, loss = 0.004325\n",
      "Dev_Accuracy @ Iteration 49: 0.890700\n",
      "Iteration 50, loss = 0.003860\n",
      "Dev_Accuracy @ Iteration 50: 0.889000\n",
      "INFO:tensorflow:Restoring parameters from ../models/section_4.1.9/baseline_dnn_model.ckpt\n",
      "验证集上的分类准确率为：0.892600\n",
      "测试集上的分类准确率为：0.893100\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "采用TensorFlow内置的前馈神经网络模块，进行时装图像的分类。\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv('../datasets/fashionmnist/fashion-mnist_train.csv')\n",
    "\n",
    "train, dev = train_test_split(train, test_size=10000, random_state=2019)\n",
    "\n",
    "test = pd.read_csv('../datasets/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "y_train = train['label'].values\n",
    "y_dev = dev['label'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "X_train = train.drop('label', axis=1)\n",
    "X_dev = dev.drop('label', axis=1)\n",
    "X_test = test.drop('label', axis=1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_dev = ss.transform(X_dev)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "train_samples, n_features = np.shape(X_train)\n",
    "dev_samples = len(X_dev)\n",
    "test_samples = len(X_test)\n",
    "\n",
    "print train_samples, dev_samples, test_samples\n",
    "\n",
    "import tensorflow as tf\n",
    "        \n",
    "n_inputs = n_features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 50\n",
    "n_outputs = 10\n",
    "batch_size = 256\n",
    "n_batches = train_samples / batch_size\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "\n",
    "#采用TensorFlow内置的前馈神经网络模块，搭建网络。\n",
    "hidden_1 = tf.layers.dense(X, n_hidden_1, name='hidden_1', activation=tf.nn.sigmoid)\n",
    "hidden_2 = tf.layers.dense(hidden_1, n_hidden_2, name='hidden_2', activation=tf.nn.sigmoid)\n",
    "logits = tf.layers.dense(hidden_2, n_outputs, name='outputs')\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    max_dev_acc = -np.inf\n",
    "    \n",
    "    for iteration in range(n_epochs):\n",
    "        for i in range(n_batches):\n",
    "            np.random.seed(iteration * n_batches + i)\n",
    "            indices = np.random.randint(train_samples, size=batch_size)\n",
    "            X_batch = X_train[indices]\n",
    "            y_batch = y_train[indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        print 'Iteration %d, loss = %f' % (iteration + 1, loss.eval(feed_dict = {X: X_train, y: y_train}))\n",
    "        \n",
    "        dev_acc = accuracy.eval(feed_dict = {X: X_dev, y: y_dev})\n",
    "        \n",
    "        print 'Dev_Accuracy @ Iteration %d: %f' % (iteration + 1, dev_acc)\n",
    "        if max_dev_acc < dev_acc:\n",
    "            saver.save(sess, '../models/section_4.1.9/baseline_dnn_model.ckpt')\n",
    "            print '#### Save model @ Iteration %d ####' %(iteration + 1)\n",
    "            max_dev_acc = dev_acc\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    # 加载所有相关参数。\n",
    "    saver.restore(sess, '../models/section_4.1.9/baseline_dnn_model.ckpt')\n",
    "    print '验证集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_dev, y: y_dev})\n",
    "    print '测试集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_test, y: y_test})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:26: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "/Users/michael/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.383183\n",
      "Dev_Accuracy @ Iteration 1: 0.858400\n",
      "#### Save model @ Iteration 1 ####\n",
      "Iteration 2, loss = 0.337155\n",
      "Dev_Accuracy @ Iteration 2: 0.860000\n",
      "#### Save model @ Iteration 2 ####\n",
      "Iteration 3, loss = 0.295768\n",
      "Dev_Accuracy @ Iteration 3: 0.870100\n",
      "#### Save model @ Iteration 3 ####\n",
      "Iteration 4, loss = 0.283769\n",
      "Dev_Accuracy @ Iteration 4: 0.869800\n",
      "Iteration 5, loss = 0.251309\n",
      "Dev_Accuracy @ Iteration 5: 0.874700\n",
      "#### Save model @ Iteration 5 ####\n",
      "Iteration 6, loss = 0.247679\n",
      "Dev_Accuracy @ Iteration 6: 0.873900\n",
      "Iteration 7, loss = 0.230681\n",
      "Dev_Accuracy @ Iteration 7: 0.872100\n",
      "Iteration 8, loss = 0.213898\n",
      "Dev_Accuracy @ Iteration 8: 0.878300\n",
      "#### Save model @ Iteration 8 ####\n",
      "Iteration 9, loss = 0.195100\n",
      "Dev_Accuracy @ Iteration 9: 0.878300\n",
      "Iteration 10, loss = 0.185096\n",
      "Dev_Accuracy @ Iteration 10: 0.878200\n",
      "Iteration 11, loss = 0.169739\n",
      "Dev_Accuracy @ Iteration 11: 0.881200\n",
      "#### Save model @ Iteration 11 ####\n",
      "Iteration 12, loss = 0.169289\n",
      "Dev_Accuracy @ Iteration 12: 0.875700\n",
      "Iteration 13, loss = 0.159166\n",
      "Dev_Accuracy @ Iteration 13: 0.880400\n",
      "Iteration 14, loss = 0.150826\n",
      "Dev_Accuracy @ Iteration 14: 0.872500\n",
      "Iteration 15, loss = 0.138814\n",
      "Dev_Accuracy @ Iteration 15: 0.881400\n",
      "#### Save model @ Iteration 15 ####\n",
      "Iteration 16, loss = 0.121215\n",
      "Dev_Accuracy @ Iteration 16: 0.880800\n",
      "Iteration 17, loss = 0.119517\n",
      "Dev_Accuracy @ Iteration 17: 0.879000\n",
      "Iteration 18, loss = 0.106504\n",
      "Dev_Accuracy @ Iteration 18: 0.881700\n",
      "#### Save model @ Iteration 18 ####\n",
      "Iteration 19, loss = 0.096510\n",
      "Dev_Accuracy @ Iteration 19: 0.881900\n",
      "#### Save model @ Iteration 19 ####\n",
      "Iteration 20, loss = 0.105923\n",
      "Dev_Accuracy @ Iteration 20: 0.873900\n",
      "Iteration 21, loss = 0.082481\n",
      "Dev_Accuracy @ Iteration 21: 0.875000\n",
      "Iteration 22, loss = 0.076789\n",
      "Dev_Accuracy @ Iteration 22: 0.883700\n",
      "#### Save model @ Iteration 22 ####\n",
      "Iteration 23, loss = 0.075831\n",
      "Dev_Accuracy @ Iteration 23: 0.881200\n",
      "Iteration 24, loss = 0.069806\n",
      "Dev_Accuracy @ Iteration 24: 0.886800\n",
      "#### Save model @ Iteration 24 ####\n",
      "Iteration 25, loss = 0.079730\n",
      "Dev_Accuracy @ Iteration 25: 0.880300\n",
      "Iteration 26, loss = 0.070460\n",
      "Dev_Accuracy @ Iteration 26: 0.881600\n",
      "Iteration 27, loss = 0.061727\n",
      "Dev_Accuracy @ Iteration 27: 0.881300\n",
      "Iteration 28, loss = 0.046217\n",
      "Dev_Accuracy @ Iteration 28: 0.886200\n",
      "Iteration 29, loss = 0.055170\n",
      "Dev_Accuracy @ Iteration 29: 0.882700\n",
      "Iteration 30, loss = 0.058727\n",
      "Dev_Accuracy @ Iteration 30: 0.886600\n",
      "Iteration 31, loss = 0.044701\n",
      "Dev_Accuracy @ Iteration 31: 0.883200\n",
      "Iteration 32, loss = 0.057402\n",
      "Dev_Accuracy @ Iteration 32: 0.875800\n",
      "Iteration 33, loss = 0.054681\n",
      "Dev_Accuracy @ Iteration 33: 0.882700\n",
      "Iteration 34, loss = 0.036966\n",
      "Dev_Accuracy @ Iteration 34: 0.888000\n",
      "#### Save model @ Iteration 34 ####\n",
      "Iteration 35, loss = 0.043244\n",
      "Dev_Accuracy @ Iteration 35: 0.883200\n",
      "Iteration 36, loss = 0.029383\n",
      "Dev_Accuracy @ Iteration 36: 0.882100\n",
      "Iteration 37, loss = 0.053467\n",
      "Dev_Accuracy @ Iteration 37: 0.881400\n",
      "Iteration 38, loss = 0.034718\n",
      "Dev_Accuracy @ Iteration 38: 0.881900\n",
      "Iteration 39, loss = 0.053172\n",
      "Dev_Accuracy @ Iteration 39: 0.876800\n",
      "Iteration 40, loss = 0.028669\n",
      "Dev_Accuracy @ Iteration 40: 0.884000\n",
      "Iteration 41, loss = 0.023157\n",
      "Dev_Accuracy @ Iteration 41: 0.884600\n",
      "Iteration 42, loss = 0.038221\n",
      "Dev_Accuracy @ Iteration 42: 0.885700\n",
      "Iteration 43, loss = 0.028749\n",
      "Dev_Accuracy @ Iteration 43: 0.882000\n",
      "Iteration 44, loss = 0.022190\n",
      "Dev_Accuracy @ Iteration 44: 0.884400\n",
      "Iteration 45, loss = 0.024318\n",
      "Dev_Accuracy @ Iteration 45: 0.884000\n",
      "Iteration 46, loss = 0.029615\n",
      "Dev_Accuracy @ Iteration 46: 0.877300\n",
      "Iteration 47, loss = 0.022868\n",
      "Dev_Accuracy @ Iteration 47: 0.887800\n",
      "Iteration 48, loss = 0.020420\n",
      "Dev_Accuracy @ Iteration 48: 0.885700\n",
      "Iteration 49, loss = 0.021204\n",
      "Dev_Accuracy @ Iteration 49: 0.884000\n",
      "Iteration 50, loss = 0.020054\n",
      "Dev_Accuracy @ Iteration 50: 0.886800\n",
      "INFO:tensorflow:Restoring parameters from ../models/section_4.1.9/bn_dnn_model.ckpt\n",
      "验证集上的分类准确率为：0.888000\n",
      "测试集上的分类准确率为：0.888700\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "采用TensorFlow内置的前馈神经网络模块，进行时装图像的分类。\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train = pd.read_csv('../datasets/fashionmnist/fashion-mnist_train.csv')\n",
    "\n",
    "train, dev = train_test_split(train, test_size=10000, random_state=2019)\n",
    "\n",
    "test = pd.read_csv('../datasets/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "y_train = train['label'].values\n",
    "y_dev = dev['label'].values\n",
    "y_test = test['label'].values\n",
    "\n",
    "X_train = train.drop('label', axis=1)\n",
    "X_dev = dev.drop('label', axis=1)\n",
    "X_test = test.drop('label', axis=1)\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_dev = ss.transform(X_dev)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "train_samples, n_features = np.shape(X_train)\n",
    "dev_samples = len(X_dev)\n",
    "test_samples = len(X_test)\n",
    "\n",
    "print train_samples, dev_samples, test_samples\n",
    "\n",
    "import tensorflow as tf\n",
    "        \n",
    "n_inputs = n_features\n",
    "n_hidden_1 = 300\n",
    "n_hidden_2 = 50\n",
    "n_outputs = 10\n",
    "batch_size = 256\n",
    "n_batches = train_samples / batch_size\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "#采用TensorFlow内置的前馈神经网络模块，搭建网络。\n",
    "hidden_1 = tf.layers.dense(X, n_hidden_1, name='hidden_1', activation=None)\n",
    "hidden_bn_1 = tf.layers.batch_normalization(hidden_1, training=is_training)\n",
    "hidden_bn_1_out = tf.nn.sigmoid(hidden_bn_1)\n",
    "\n",
    "hidden_2 = tf.layers.dense(hidden_bn_1_out, n_hidden_2, name='hidden_2', activation=None)\n",
    "hidden_bn_2 = tf.layers.batch_normalization(hidden_2, training=is_training)\n",
    "hidden_bn_2_out = tf.nn.sigmoid(hidden_bn_2)\n",
    "\n",
    "logits = tf.layers.dense(hidden_bn_2_out, n_outputs, name='outputs')\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "\n",
    "loss = tf.reduce_mean(xentropy, name='loss')\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.control_dependencies(update_ops):\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    max_dev_acc = -np.inf\n",
    "    \n",
    "    for iteration in range(n_epochs):\n",
    "        for i in range(n_batches):\n",
    "            np.random.seed(iteration * n_batches + i)\n",
    "            indices = np.random.randint(train_samples, size=batch_size)\n",
    "            X_batch = X_train[indices]\n",
    "            y_batch = y_train[indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, is_training: True})\n",
    "        print 'Iteration %d, loss = %f' % (iteration + 1, loss.eval(feed_dict = {X: X_train, y: y_train, is_training: False}))\n",
    "        \n",
    "        dev_acc = accuracy.eval(feed_dict = {X: X_dev, y: y_dev, is_training: False})\n",
    "        \n",
    "        print 'Dev_Accuracy @ Iteration %d: %f' % (iteration + 1, dev_acc)\n",
    "        if max_dev_acc < dev_acc:\n",
    "            saver.save(sess, '../models/section_4.1.9/bn_dnn_model.ckpt')\n",
    "            print '#### Save model @ Iteration %d ####' %(iteration + 1)\n",
    "            max_dev_acc = dev_acc\n",
    "        \n",
    "with tf.Session() as sess:\n",
    "    # 加载所有相关参数。\n",
    "    saver.restore(sess, '../models/section_4.1.9/bn_dnn_model.ckpt')\n",
    "    print '验证集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_dev, y: y_dev, is_training: False})\n",
    "    print '测试集上的分类准确率为：%f' % accuracy.eval(feed_dict = {X: X_test, y: y_test, is_training: False})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
