{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('sklearn test!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR and SGD test begin!\n",
      "lr--report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      0.99      0.99       100\n",
      "           4       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "sgdc--report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           2       0.99      0.99      0.99       100\n",
      "           4       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.99       171\n",
      "   macro avg       0.99      0.99      0.99       171\n",
      "weighted avg       0.99      0.99      0.99       171\n",
      "\n",
      "LR and SGD test end!\n"
     ]
    }
   ],
   "source": [
    "print('LR and SGD test begin!')\n",
    "# logistic regression\n",
    "# SGD 分类\n",
    "# 乳腺癌肿瘤预测\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "column_names = ['code number','feature1','feature2','feature3','feature4','feature5','feature6','feature7','feature8','feature9','class_label']\n",
    "# dataset =pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data',names=column_names)\n",
    "# 导入数据\n",
    "dataset = pd.read_csv('./dataset/breast-cancer-wisconsin.csv')\n",
    "dataset = dataset.replace('?',np.nan)\n",
    "# print('dataset shape:',dataset.shape)\n",
    "dataset = dataset.dropna(how='any')\n",
    "# print('dataset shape:',dataset.shape)\n",
    "\n",
    "# cross_validation 交叉检验\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(dataset[column_names[1:9]], dataset[column_names[-1]], test_size=0.25, random_state=33)\n",
    "# print(x_train.shape,x_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# 归一化处理 standardscaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "# print(x_train)\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test  = ss.transform(x_test)\n",
    "# print(x_train)\n",
    "\n",
    "# LogisticRegression和SGDclassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# 实例化\n",
    "lr = LogisticRegression()\n",
    "sgdc = SGDClassifier()\n",
    "\n",
    "# 模型拟合\n",
    "lr.fit(x_train,y_train)\n",
    "sgdc.fit(x_train,y_train)\n",
    "\n",
    "# 预测\n",
    "lr_y_predict = lr.predict(x_test)\n",
    "sgdc_y_predict = sgdc.predict(x_test)\n",
    "\n",
    "# 模型报告\n",
    "from sklearn.metrics import classification_report\n",
    "lr_report = classification_report(y_test, lr_y_predict, target_names=['2','4'])\n",
    "sgdc_report = classification_report(y_test, sgdc_y_predict, target_names=['2','4'])\n",
    "print('lr--report:\\n',lr_report)\n",
    "print('sgdc--report:\\n',sgdc_report)\n",
    "\n",
    "print('LR and SGD test end!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVC test begin!\n",
      "linear svc test score: 0.9533333333333334\n",
      "linear svc train score: 0.9933184855233853\n",
      "\n",
      "linear svc classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       0.96      0.98      0.97        54\n",
      "           2       0.98      1.00      0.99        44\n",
      "           3       0.93      0.93      0.93        46\n",
      "           4       0.97      1.00      0.99        35\n",
      "           5       0.94      0.94      0.94        48\n",
      "           6       0.96      0.98      0.97        51\n",
      "           7       0.92      1.00      0.96        35\n",
      "           8       0.98      0.84      0.91        58\n",
      "           9       0.95      0.91      0.93        44\n",
      "\n",
      "    accuracy                           0.95       450\n",
      "   macro avg       0.95      0.96      0.95       450\n",
      "weighted avg       0.95      0.95      0.95       450\n",
      "\n",
      "SVC test end!\n"
     ]
    }
   ],
   "source": [
    "print('SVC test begin!')\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "# print(digits.data.shape)\n",
    "\n",
    "# 数据分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=33)\n",
    "# print(x_train.shape,x_test.shape)\n",
    "\n",
    "# 标准化处理\n",
    "# print(pd.unique(x_train[:,1]))\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "# 模型拟合\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(x_train,y_train)\n",
    "y_predict = lsvc.predict(x_test)\n",
    "\n",
    "# 评估\n",
    "print('linear svc test score:',lsvc.score(x_test,y_test))\n",
    "print('linear svc train score:',lsvc.score(x_train,y_train))\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test,y_predict,target_names=digits.target_names.astype(str))      \n",
    "print('\\nlinear svc classification report:\\n',cr)\n",
    "\n",
    "\n",
    "print('SVC test end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bayes test begin!\n",
      "\n",
      "naive bayes test report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.86      0.86      0.86       201\n",
      "           comp.graphics       0.59      0.86      0.70       250\n",
      " comp.os.ms-windows.misc       0.89      0.10      0.17       248\n",
      "comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240\n",
      "   comp.sys.mac.hardware       0.93      0.78      0.85       242\n",
      "          comp.windows.x       0.82      0.84      0.83       263\n",
      "            misc.forsale       0.91      0.70      0.79       257\n",
      "               rec.autos       0.89      0.89      0.89       238\n",
      "         rec.motorcycles       0.98      0.92      0.95       276\n",
      "      rec.sport.baseball       0.98      0.91      0.95       251\n",
      "        rec.sport.hockey       0.93      0.99      0.96       233\n",
      "               sci.crypt       0.86      0.98      0.91       238\n",
      "         sci.electronics       0.85      0.88      0.86       249\n",
      "                 sci.med       0.92      0.94      0.93       245\n",
      "               sci.space       0.89      0.96      0.92       221\n",
      "  soc.religion.christian       0.78      0.96      0.86       232\n",
      "      talk.politics.guns       0.88      0.96      0.92       251\n",
      "   talk.politics.mideast       0.90      0.98      0.94       231\n",
      "      talk.politics.misc       0.79      0.89      0.84       188\n",
      "      talk.religion.misc       0.93      0.44      0.60       158\n",
      "\n",
      "                accuracy                           0.84      4712\n",
      "               macro avg       0.86      0.84      0.82      4712\n",
      "            weighted avg       0.86      0.84      0.82      4712\n",
      "\n",
      "Bayes test end!\n"
     ]
    }
   ],
   "source": [
    "print('Bayes test begin!')\n",
    "# 朴素贝叶斯\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "# print(len(news.data))\n",
    "# print(news.data[0])\n",
    "\n",
    "# 数据分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(news.data,news.target,test_size=0.25,random_state=33)\n",
    "# print(len(x_train),len(x_test))\n",
    "\n",
    "# 文本特征向量转换模块\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer()\n",
    "x_train = cvect.fit_transform(x_train)\n",
    "x_test = cvect.transform(x_test)\n",
    "# print(type(x_train))\n",
    "\n",
    "# 模型拟合\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "y_predict = mnb.predict(x_test)\n",
    "\n",
    "# 模型检验\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test,y_predict,target_names=news.target_names)\n",
    "print('\\nnaive bayes test report:\\n',cr)\n",
    "\n",
    "\n",
    "print('Bayes test end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNN test begin!\n\nknn classification report:\n               precision    recall  f1-score   support\n\n      setosa       1.00      1.00      1.00         8\n  versicolor       0.73      1.00      0.85        11\n   virginica       1.00      0.79      0.88        19\n\n    accuracy                           0.89        38\n   macro avg       0.91      0.93      0.91        38\nweighted avg       0.92      0.89      0.90        38\n\nKNN test end!\n"
     ]
    }
   ],
   "source": [
    "print('KNN test begin!')\n",
    "# KNN 分类\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "# print(iris.data.shape)\n",
    "# print(iris.DESCR)\n",
    "\n",
    "# 数据分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(iris.data,iris.target,test_size=0.25,random_state=33)\n",
    "# print(x_train.shape,x_test.shape)\n",
    "\n",
    "# 数据预处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)\n",
    "\n",
    "# 模型拟合\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train)\n",
    "y_predict = knn.predict(x_test)\n",
    "\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test,y_predict,target_names=iris.target_names)\n",
    "print('\\nknn classification report:\\n',cr)\n",
    "\n",
    "print('KNN test end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trees test begin!\n",
      "\n",
      "decision tree classifier report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        died       0.78      0.91      0.84       202\n",
      "    survived       0.80      0.58      0.67       127\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.79      0.74      0.75       329\n",
      "weighted avg       0.78      0.78      0.77       329\n",
      "\n",
      "\n",
      "randomforest classifier report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        died       0.78      0.90      0.83       202\n",
      "    survived       0.79      0.59      0.68       127\n",
      "\n",
      "    accuracy                           0.78       329\n",
      "   macro avg       0.78      0.75      0.76       329\n",
      "weighted avg       0.78      0.78      0.77       329\n",
      "\n",
      "\n",
      "gradient boosting classifier report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        died       0.78      0.92      0.84       202\n",
      "    survived       0.82      0.58      0.68       127\n",
      "\n",
      "    accuracy                           0.79       329\n",
      "   macro avg       0.80      0.75      0.76       329\n",
      "weighted avg       0.80      0.79      0.78       329\n",
      "\n",
      "Trees test end!\n"
     ]
    }
   ],
   "source": [
    "print('Trees test begin!')\n",
    "import pandas as pd\n",
    "\n",
    "titanic = pd.read_csv('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt')\n",
    "# print(titanic.info())\n",
    "# print(titanic.describe())\n",
    "x = titanic[['pclass','age','sex']]\n",
    "y = titanic['survived']\n",
    "\n",
    "# age 缺失值处理\n",
    "x['age'].fillna(x['age'].mean(),inplace=True)\n",
    "# pclass sex处理\n",
    "# print(x_train.head())\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dvec = DictVectorizer(sparse=False)\n",
    "x = dvec.fit_transform(x.to_dict(orient='record'))\n",
    "# x = pd.DataFrame(x)\n",
    "# print(x.describe())\n",
    "\n",
    "# crossvalidation\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=33)\n",
    "# print(x_train.shape,x_test.shape)\n",
    "\n",
    "# 模型拟合\n",
    "# 单一决策树：decisiontree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(x_train,y_train)\n",
    "y_dtree_predict = dtree.predict(x_test)\n",
    "# 随机森林：randomforest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train,y_train)\n",
    "y_rfc_predict = rfc.predict(x_test)\n",
    "# 梯度提升决策树：gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc.fit(x_train,y_train)\n",
    "y_gbc_predict = gbc.predict(x_test)\n",
    "\n",
    "\n",
    "# classificaton report\n",
    "from sklearn.metrics import classification_report\n",
    "cr_dtree = classification_report(y_test,y_dtree_predict,target_names=['died','survived'])\n",
    "print('\\ndecision tree classifier report:\\n',cr_dtree)\n",
    "cr_rfc = classification_report(y_test,y_rfc_predict,target_names=['died','survived'])\n",
    "print('\\nrandomforest classifier report:\\n',cr_rfc)\n",
    "cr_gbc = classification_report(y_test,y_gbc_predict,target_names=['died','survived'])\n",
    "print('\\ngradient boosting classifier report:\\n',cr_gbc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Trees test end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear regression test begin!\n\nr2 score of linear regression:\t\t\t0.6758\nr2 score of sgd regression:\t\t\t0.6647\n\nmean squared error of linear regression:\t25.1392\nmean squared error of sgd regression:\t\t25.9989\n\nmean absolute error of linear regression:\t3.5325\nmean absolute error of sgd regression:\t\t3.5048\n\nLinear regression test end!\n"
     ]
    }
   ],
   "source": [
    "print('Linear regression test begin!\\n')\n",
    "# linear regression\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "# print(boston.DESCR)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,test_size=0.25,random_state=33)\n",
    "\n",
    "# 标准归一化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_x = StandardScaler()\n",
    "x_train = ss_x.fit_transform(x_train)\n",
    "x_test = ss_x.transform(x_test)\n",
    "ss_y = StandardScaler()\n",
    "y_train = ss_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = ss_y.transform(y_test.reshape(-1, 1))\n",
    "# print(y_train.shape)\n",
    "\n",
    "# 模型拟合\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_lr_predict = lr.predict(x_test)\n",
    "# sgd regressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgdr = SGDRegressor()\n",
    "sgdr.fit(x_train,y_train)\n",
    "y_sgdr_predict = sgdr.predict(x_test)\n",
    "\n",
    "# 模型评估\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "# r2_score\n",
    "r2_score_lr = r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_lr_predict))\n",
    "r2_score_sgdr = r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_sgdr_predict))\n",
    "# mean squared error\n",
    "ms_error_lr = mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_lr_predict))\n",
    "ms_error_sgdr = mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_sgdr_predict))\n",
    "# mean absolute error\n",
    "ma_error_lr = mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_lr_predict))\n",
    "ma_error_sgdr = mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_sgdr_predict))\n",
    "print('r2 score of linear regression:\\t\\t\\t%.4f'%r2_score_lr)\n",
    "print('r2 score of sgd regression:\\t\\t\\t%.4f\\n'%r2_score_sgdr)\n",
    "print('mean squared error of linear regression:\\t%.4f'%ms_error_lr)\n",
    "print('mean squared error of sgd regression:\\t\\t%.4f\\n'%ms_error_sgdr)\n",
    "print('mean absolute error of linear regression:\\t%.4f'%ma_error_lr)\n",
    "print('mean absolute error of sgd regression:\\t\\t%.4f'%ma_error_sgdr)\n",
    "\n",
    "print('\\nLinear regression test end!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVR regression test begin!\n\n\nr2_score of SVR linear regression:\t0.6507\nr2_score of SVR   poly regression:\t0.4037\nr2_score of SVR    rbf regression:\t0.7560\n\nms_error of SVR linear regression:\t27.0883\nms_error of SVR   poly regression:\t46.2417\nms_error of SVR    rbf regression:\t18.9209\n\nma_error of SVR linear regression:\t3.4328\nma_error of SVR   poly regression:\t3.7384\nma_error of SVR    rbf regression:\t2.6068\n\nSVR regression test end!\n"
     ]
    }
   ],
   "source": [
    "print('SVR regression test begin!\\n')\n",
    "# SVR regression\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "# print(boston.DESCR)\n",
    "\n",
    "# cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(boston.data,boston.target,test_size=0.25,random_state=33)\n",
    "\n",
    "# 标准归一化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss_x = StandardScaler()\n",
    "x_train = ss_x.fit_transform(x_train)\n",
    "x_test = ss_x.transform(x_test)\n",
    "ss_y = StandardScaler()\n",
    "y_train = ss_y.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test = ss_y.transform(y_test.reshape(-1, 1))\n",
    "# print(y_train.shape)\n",
    "\n",
    "# # 模型拟合\n",
    "# from sklearn.svm import SVR\n",
    "# # SVR kernel='linear'\n",
    "# svr_linear = SVR(kernel='linear')\n",
    "# svr_linear.fit(x_train,y_train)\n",
    "# y_svr_linear_predict = svr_linear.predict(x_test)\n",
    "# # SVR kernel='poly'\n",
    "# svr_poly = SVR(kernel='poly')\n",
    "# svr_poly.fit(x_train,y_train)\n",
    "# y_svr_poly_predict = svr_poly.predict(x_test)\n",
    "# # SVR kernel='rbf'\n",
    "# svr_rbf = SVR(kernel='rbf')\n",
    "# svr_rbf.fit(x_train,y_train)\n",
    "# y_svr_rbf_predict = svr_rbf.predict(x_test)\n",
    "\n",
    "# # 模型评估\n",
    "# from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "# # r2_score\n",
    "# r2_score_svr_linear = r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_linear_predict))\n",
    "# r2_score_svr_poly = r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_poly_predict))\n",
    "# r2_score_svr_rbf = r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_rbf_predict))\n",
    "# # mean squared error\n",
    "# ms_error_svr_linear = mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_linear_predict))\n",
    "# ms_error_svr_poly = mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_poly_predict))\n",
    "# ms_error_svr_rbf = mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_rbf_predict))\n",
    "# # mean absolute error\n",
    "# ma_error_svr_linear = mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_linear_predict))\n",
    "# ma_error_svr_poly = mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_poly_predict))\n",
    "# ma_error_svr_rbf = mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(y_svr_rbf_predict))\n",
    "# print('r2 score of SVR linear regression:\\t\\t\\t%.4f'%r2_score_svr_linear)\n",
    "# print('r2 score of SVR poly regression:\\t\\t\\t%.4f'%r2_score_svr_poly)\n",
    "# print('r2 score of SVR rbf regression:\\t\\t\\t\\t%.4f\\n'%r2_score_svr_rbf)\n",
    "\n",
    "# print('mean squared error of SVR linear regression:\\t\\t%.4f'%ms_error_svr_linear)\n",
    "# print('mean squared error of SVR poly regression:\\t\\t%.4f'%ms_error_svr_poly)\n",
    "# print('mean squared error of SVR rbf regression:\\t\\t%.4f\\n'%ms_error_svr_rbf)\n",
    "\n",
    "# print('mean absolute error of SVR linear regression:\\t\\t%.4f'%ma_error_svr_linear)\n",
    "# print('mean absolute error of SVR poly regression:\\t\\t%.4f'%ma_error_svr_poly)\n",
    "# print('mean absolute error of SVR rbf regression:\\t\\t%.4f'%ma_error_svr_rbf)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "model_data = {'svr_ins':{},'y_predict':{},'r2_score':{},'ms_error':{},'ma_error':{}}\n",
    "kernel_list = ['linear','poly','rbf']\n",
    "for svr_kernel in kernel_list:\n",
    "    model_data['svr_ins'][svr_kernel] =  SVR(kernel=svr_kernel)\n",
    "    model_data['svr_ins'][svr_kernel].fit(x_train,y_train)\n",
    "    model_data['y_predict'][svr_kernel] = model_data['svr_ins'][svr_kernel].predict(x_test)\n",
    "    model_data['r2_score'][svr_kernel] = r2_score(ss_y.inverse_transform(y_test), ss_y.inverse_transform(model_data['y_predict'][svr_kernel]))\n",
    "    model_data['ms_error'][svr_kernel] = mean_squared_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(model_data['y_predict'][svr_kernel]))\n",
    "    model_data['ma_error'][svr_kernel] = mean_absolute_error(ss_y.inverse_transform(y_test), ss_y.inverse_transform(model_data['y_predict'][svr_kernel]))\n",
    "score_list = ['r2_score','ms_error','ma_error']\n",
    "for svr_score in score_list:\n",
    "    print()\n",
    "    for svr_kernel in kernel_list:\n",
    "        print('%8s of SVR %6s regression:\\t%.4f'%(svr_score, svr_kernel, model_data[svr_score][svr_kernel]))\n",
    "\n",
    "\n",
    "\n",
    "print('\\nSVR regression test end!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a175d104",
   "language": "python",
   "display_name": "PyCharm (mine)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}